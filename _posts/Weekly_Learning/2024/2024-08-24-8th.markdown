---
layout:     post
title:      "2024-每周补脑8th"
subtitle:   ""
date:       2024-08-24 06:16:00
author:     "XiLock"
header-img: "img/in-post/2018/wl-bg.jpg"
header-mask: 0.3
catalog:    true
tags:
    - 每周补脑
    - 2024


---

### 科学


### 言论
1. 你的孩子选课题，应该是在半夜3点钟悄悄进入前沿阵地。 等孩子毕业了， 正好天亮了，找工作。等到能独挡一面的时候，正好中午12点，如日中天。相反，你若选一个正热门的、相当于下午两点钟太阳的课题，等毕业了，太阳正好下山。所以，就算你不打算做科研，也不要去跟风。  -- [朱松纯](http://www.stat.ucla.edu/%7Esczhu/research_blog.html#VisionHistory)
1. “你看这头条新闻，但是，头条天天换。你再看教科书上的东西，它永远就在那里。我们不要做上头条的东西、要做能进教科书的东西。”。  -- [朱松纯引用Roger Brockett语录](http://www.stat.ucla.edu/%7Esczhu/research_blog.html#VisionHistory)
1. 谷歌待了九年后，我在本周离职。回顾这九年，我得到了很多东西。首先，我得到了大量的钱。其次，我得到了工程技能，理解了复杂的大型网站系统，还拥有处理生产故障和调试机器的世界一流的技能。再次，我得到了领导和管理团队的技能，以及成为一家巨型技术公司一员的满足感。最后，我得到了各种福利，比如办公室、游泳池、健身房、体育课程、每周按摩、美味和健康的膳食、医疗保健等，还有好玩且舒适的异地出差和商务旅行机会。但现在的谷歌，相比我刚加入时，发生了很多变化，已经不再那么有趣和酷炫了。以前，谷歌的技术是顶尖的。现在，其他公司的技术水平，正在接近谷歌。谷歌的内部预算也在削减，我们的商务旅行减少了，裁员不断。公司还把招聘名额转移到更廉价的地区。这对我产生了直接影响，我没法为自己的团队招人了。这些年来，谷歌内部的安全制度和规章，不断增加，越来越繁琐。公司的内部系统，以及各种团队之间的关系，变得非常复杂。这减慢了我们的开发速度，并带来了许多艰巨的工程挑战。对于我们来说，理解公司内部系统，成了越来越大的负担。你需要牢记无数的系统和技术细节，其中任何一个都可能对你产生影响（对于 SRE 工程师尤其如此）。新入职的员工可能需要一年的时间才能完全理解这些东西，这太疯狂了。很多时候，我觉得自己被会议、重复性劳动、资源不足的团队工作，压得喘不过气，但同时又没有良好的成长机会。公司两次承诺我，可以扩招手下的员工，但是两次都被取消了。我觉得，现在的工作没有充分发挥我的能力，但是在公司内部，又找不到发挥的方式。与此同时，谷歌的高管们不提供支持和反馈，也几乎没有任何监督。你问他们下一步如何开展工作，他们会不知所措，让你自己去解决。我在谷歌看不到大的升迁机会。我已经是 L6 工程师了，在工程领域到顶了。我对 L7 并不真正感兴趣，因为 L7 更多是一种政治角色，不是工程角色，并且也很难说手下会管理多少人。如果我有机会自己领导一个大团队，我可能愿意留下来，否则我更渴望创办自己的公司。回顾这九年，我感到自己很幸运。谷歌的股票表现非常好，再加上我的快速晋升和高绩效，使得个人收入很不错。我经过仔细思考后，对这些收入做出的财务决策，也很正确，给我带来了更多财务回报。我在谷歌认识了大量的人，建立了许多关系。我雇用的员工也都非常可靠。我有一些后悔没有做的事情。最主要的就是，我本应该早点退出 SRE，申请转移到其他国家，从一开始我就知道 SRE 不是我想要的。**我只是坐等情况发生变化，结果没有如愿，现在我知道了，我应该主动寻求变化。** -- [Postmortem of my 9 year journey at Google](https://tinystruggles.com/posts/google_postmortem/)
1. 大家都认为 Nvidia 是销售 GPU（显卡）的公司，但是实际上他们是在销售 CUDA 加速运算库，GPU 只是非常昂贵又必不可少的独家配件。 -- [HackNews](https://news.ycombinator.com/item?id=41361597)
1. 我的职业建议是，任何工作要么让你学习（learn），要么让你赚钱（earn）。如果既学不到新东西，又赚不到钱，你就应该走了。 -- [Garry Tan，硅谷风险投资家](https://beabytes.com/seafaring-part-i/)


### 观点
###### [朱松纯：正本清源，浅谈人工智能现状、任务、构架与统一](http://www.stat.ucla.edu/%7Esczhu/research_blog.html#VisionHistory) 
1.  鹦鹉有很强的语言模仿能力，你说一个短句，多说几遍，它能重复，这就类似于当前的由数据驱动的聊天机器人。二者都可以说话，但鹦鹉和聊天机器人都不明白说话的语境和语义，也就是它们不能把说的话对应到物理世界和社会的物体、场景、人物，不符合因果与逻辑。 可是，乌鸦就远比鹦鹉聪明，它们能够制造工具，懂得各种物理的常识和人的活动的社会常识。
1. 讲通俗一点，我们要寻找“乌鸦”模式的智能，而不要“鹦鹉”模式的智能。当然，我们必须也要看到，“鹦鹉”模式的智能在商业上，针对某些垂直应用或许有效。但也不是说要把所有智能问题都解决了，才能做商业应用。单项技术如果成熟落地，也可以有巨大商业价值。我这里谈的是科学研究的目标。 
1. 乌鸦把坚果从天上往下抛，发现解决不了这个任务。在这个过程中，它就发现一个诀窍，把果子放到路上让车轧过去，这就是“鸟机交互”了。后来进一步发现，虽然坚果被轧碎了，但它到路中间去吃是一件很危险的事。因为在一个车水马龙的路面上，随时它就牺牲了。我这里要强调一点，这个过程是没有大数据训练的，也没有所谓监督学习，乌鸦的生命没有第二次机会。这是与当前很多机器学习，特别是深度学习完全不同的机制。 
1. 然后，它又开始观察了，它发现在靠近红绿路灯的路口，车子和人有时候停下了。这时，它必须进一步领悟出红绿灯、斑马线、行人指示灯、车子停、人流停这之间复杂的因果链。甚至，哪个灯在哪个方向管用、对什么对象管用。搞清楚之后，乌鸦就选择了一根正好在斑马线上方的一根电线，蹲下来了。这里我要强调另一点，也许它观察和学习的是别的地点，那个点没有这些蹲点的条件。它必须相信，同样的因果关系，可以搬到当前的地点来用。这一点，当前很多机器学习方法是做不到的。比如，一些增强学习方法，让机器人抓取一些固定物体，如积木玩具，换一换位置都不行；打游戏的人工智能算法，换一换画面，又得重新开始学习。
1. 智能是一种现象，表现在个体和社会群体的行为过程中。回到前面乌鸦的例子，我认为智能系统的根源可以追溯到两个基本前提条件： 一、物理环境客观的现实与因果链条。这是外部物理环境给乌鸦提供的、生活的边界条件。在不同的环境条件下，智能的形式会是不一样的。任何智能的机器必须理解物理世界及其因果链条，适应这个世界。  二、智能物种与生俱来的任务与价值链条。这个任务是一个生物进化的“刚需”。如个体的生存，要解决吃饭和安全问题，而物种的传承需要交配和社会活动。这些基本任务会衍生出大量的其它的“任务”。动物的行为都是被各种任务驱动的。任务代表了价值观和决策函数，这些价值函数很多在进化过程中就已经形成了，包括人脑中发现的各种化学成分的奖惩调制，如多巴胺（快乐）、血清素（痛苦）、乙酰胆碱（焦虑、不确定性）、去甲肾上腺素（新奇、兴奋）等。 有了物理环境的因果链和智能物种的任务与价值链，那么一切都是可以推导出来的。要构造一个智能系统，如机器人或者游戏环境中的虚拟的人物，我们先给他们定义好身体的基本行动的功能，再定一个模型的空间（包括价值函数）。其实，生物的基因也就给了每个智能的个体这两点。然后，它就降临在某个环境和社会群体之中，就应该自主地生存，就像乌鸦那样找到一条活路:认识世界、利用世界、改造世界。 这里说的模型的空间是一个数学的概念，我们人脑时刻都在改变之中，也就是一个抽象的点，在这个空间中移动。模型的空间通过价值函数、决策函数、感知、认知、任务计划等来表达。通俗来说，一个脑模型就是世界观、人生观、价值观的一个数学的表达。这个空间的复杂度决定了个体的智商和成就。
1. 是什么驱动了模型在空间中的运动，也就是学习的过程？还是两点： 一、 外来的数据。外部世界通过各种感知信号，传递到人脑，塑造我们的模型。数据来源于观察（observation）和实践（experimentation）。观察的数据一般用于学习各种统计模型，这种模型就是某种时间和空间的联合分布，也就是统计的关联与相关性。实践的数据用于学习各种因果模型，将行为与结果联系在一起。因果与统计相关是不同的概念。   17 二、内在的任务。这就是由内在的价值函数驱动的行为、以期达到某种目的。我们的价值函数是在生物进化过程中形成的。因为任务的不同，我们往往对环境中有些变量非常敏感，而对其它一些变量不关心。由此，形成不同的模型。
1. 是什么驱动了模型在空间中的运动，也就是学习的过程？还是两点一、 外来的数据。外部世界通过各种感知信号，传递到人脑，塑造我们的模型。数据来源于观察（observation）和实践（experimentation）。观察的数据一般用于学习各种统计模型，这种模型就是某种时间和空间的联合分布，也就是统计的关联与相关性。实践的数据用于学习各种因果模型，将行为与结果联系在一起。因果与统计相关是不同的概念。   17 二、内在的任务。这就是由内在的价值函数驱动的行为、以期达到某种目的。我们的价值函数是在生物进化过程中形成的。因为任务的不同，我们往往对环境中有些变量非常敏感，而对其它一些变量不关心。由此，形成不同的模型。 
1. 任何一个模型由数据与任务来共同塑造。
1. 当前的很多深度学习方法，属于一个被我称作“大数据、小任务范式（big data for small task）”。针对某个特定的任务，如人脸识别和物体识别，设计一个简单的价值函数Loss function，用大量数据训练特定的模型。这种方法在某些问题上也很有效。但是，造成的结果是，这个模型不能泛化和解释。所谓泛化就是把模型用到其它任务，解释其实也是一种复杂的任务。这是必然的结果：你种的是瓜， 怎么希望得豆呢？ 我多年来一直在提倡的一个相反的思路：人工智能的发展，需要进入一个“小数据、大任务范式（small data for big tasks）”，要用大量任务、而不是大量数据来塑造智能系统和模型。在哲学思想上，必须有一个思路上的大的转变和颠覆。自然辨证法里面，恩格斯讲过，“劳动创造了人”，这个有点争议。我认为一个更合适的说法是“任务塑造了智能”。人的各种感知和行为，时时刻刻都是被任务驱动的。
1. 几何重建的一个很重要的背景是，我们往往不需要追求十分精确的深度位置。比如，人对三维的感知其实都是非常不准的，它的精确度取决于你当前要执行的任务。在执行的过程中，你不断地根据需要来提高精度。比如，你要去拿几米以外的一个杯子，一开始你对杯子的方位只是一个大致的估计，在你走近、伸手的过程中逐步调整精度。
1. 每个场景底下其实就分解成为一些动作和功能 ，由计算机想象、推理的各种功能决定对场景的分类。 想象功能就是把人的各种姿态放到三维场景中去拟合。这是完全不同于当前的深度学习方法用的分类方法。
1. 我们的生活空间除了满足人类的各种需求（功能、任务）之外， 另一个基本约束就是物理。我们对图像的解释和理解被表达成为一个解译图，这个解译图必须满足物理规律，否则就是错误的。比如稳定性是人可以快速感知的，如果你发现周围东西不稳，要倒了，你反应非常快，赶紧闪开。
1. 现在科研的一个现实是走向“娱乐化”：肤浅的歌曲流行，大家都能唱，复杂高深的东西大家躲着走。 
1. 。所谓刷榜，一般是下载了人家的代码，改进、调整、搭建更大模块，这样速度快。我曾经访问一家技术很牛的中国公司（不是搞视觉的），那个公司的研发主管非常骄傲，说他们刷榜总是赢，美国一流大学都不在话下。我听得不耐烦了，我说人家就是两个学生在那里弄，你们这么大个团队在这里刷，你代码里面基本没有算法是你自己的。如果人家之前不公布代码，你们根本没法玩。很多公司就拿这种刷榜的结果宣传自己超过了世界一流水平。 
1. 为什么我们不需要大数据的学习模式，而是靠举一反三的能力。 我们人是非常功利的社会动物，就是说做什么事情都是被任务所驱动的。这一点，2000 年前的司马迁就已经远在西方功利哲学之前看到了（ 《史记》 “货殖列传” ）： “天下熙熙，皆为利来；天下攘攘，皆为利往。” 那么，人也就带着功利的目的来看待这个世界，这叫做“teleological stance”。这个物体是用来干什么的？它对我有什么用？怎么用？ 当然，有没有用是相对于我们手头的任务来决定的。很多东西，当你用不上的时候，往往视而不见；一旦要急用，你就会当个宝。俗话叫做“势利眼”，没办法，这是人性！你今天干什么、明天干什么，每时每刻都有任务。俗话又叫做“屁股决定脑袋”，一个官员坐在不同位置，他就有不同的任务与思路，位置一调，马上就“物是人非”了。 
1. 如何才能看到这些蛛丝马迹呢？其一、你需要大量的知识，这个知识来源于图像之外，是你想象的过程中用到的，比如一个头发怎么掉在这里的？还有就是行为的动机目的，犯案人员到底想改变什么“流态”？ 我把这些图像之外的东西统称为“暗物质”--- Dark Matter。物理学家认为我们可观察的物质和能量只是占宇宙总体的 5%，剩下的 95%是观察不到的暗物质和暗能量。视觉与此十分相似：感知的图像往往只占5%，提供一些蛛丝马迹；而后面的 95%，包括功能、物理、因果、动机等等是要靠人的想象和推理过程来完成的。
1. 我们把对这个物理空间、动作、因果的理解还是表达成为一个Spatial，Temporal and Causal Parse Graph（STC-PG）。这个STCPG包含了你对空间的理解（物体、三维形状、材质等）、时间上动作的规划、因果的推理。最好是这样子砸，它物理因果能够实现，可能会被砸开，再连在一块来求解，求时间、空间和因果的这么一个解析图，就是一个解。也就是，最后你达到目的，改变了某种物理的流态。 我再强调几点： 一、这个STC-PG的表达是你想象出来的。这个理解的过程是在你动手之前就想好了的，它里面的节点和边界大多数在图像中是没有的，也就是我称作的“暗物质”。 二、这个计算的过程中，大量的运算属于“top-down”自顶向下的计算过程。也就是用你脑皮层里面学习到的大量的知识来解释你看到的“蛛丝马迹”，形成一个合理的解。而这种Top-down的计算过程在目前的深度多层神经网络中是没有的。神经网络只有feedforward 向上逐层传播信息。你可能要说了，那不是有 Backpropagation 吗？那不是top-down。一年前，LeCun来UCLA做讲座，他看到我在座，就说DNN目前缺乏朱教授一直提倡的Top-Down计算进程。 三、学习这个任务只需要极少的几个例子。如果一个人要太多的例子，说明Ta脑袋“不开窍”，智商不够。顺便说一句，我在UCLA讲课，期末学生会给老师评估教学质量。一个常见的学生意见就是朱教授给的例子太少了。对不起，我没时间给你上课讲那么多例子，靠做题、题海训练，那不是真本事，也不是学习的本质。子曰：“学而不思则罔，思而不学则殆”。这里的“思”应该是推理，对于自然界或者社会的现象、行为和任务，形成一个符合规律的自洽的解释，在我看来就是一个STC-PG。
1. 计算机视觉要继续发展，必须发掘这些“dark matter”。把图像中想象的 95%的暗物质与图像中可见的 5%的蛛丝马迹，结合起来思考，才能到达真正的理解。现在大家都喜欢在自己工作前面加一个Deep，以为这样就算深刻了、深沉了，但其实还是非常肤浅的。不管你多深，不管你卷积神经网络多少层，它只是处理可见的图像表观特征、语音特征，没有跳出那5%。：Go Dark， Beyond Deep --- 发掘暗，超越深。
1. 语言的起源就是要把一个人脑袋（mind）的一个信息表达传给你一个人，这就包括上一节讲的知识、注意、意向计划，归纳为图中那三个三角形的表达。希望通过对话形成共识，形成共同的任务规划，就是我们一致行动。所以，语言产生的基础是人要寻求合作。 动物之间就已经有丰富的交流的方式，很多借助于肢体语言。人的对话不一定用语言，手语、哑剧（pantomine）同样可以传递很多信息。所以，在语言产生之前，人类就已经有了十分丰富的认知基础，没有这样的认知基础，语言是空洞的符号，对话也不可能发生。除了需要这个认知基础，语言的研究不能脱离了视觉对外部世界的感知、机器人运动的因果推理，否则语言就是无源之水、无本之木。这也就是为什么当前一些聊天机器人都在“扯白”。  
1. 如果没有这个共同的外部世界，那我根本就不知道你在说什么。比如外国人聚在一起讲一个笑话，我们可能听不懂。
1. 乙脑袋里面是否与甲有一个共同的世界模型？否则，解码之后，乙也不能领会里面的内容？或者会误解。那么我发这个信息的时候，措辞要尽量减少这样的误解。
1. 人脸是个概念，所有的人脸就是在这一百万维空间的一个子集，但是这个子集和其它个子集要发生关系，这个关系叫拓扑关系。计算机的人把它叫做语法，对应于代数拓扑。比如，头和脖子在肩膀上是合规的，概率很高。这个图像空间的结构其实就是语法，这个语法就是时空因果的与或图。
1. 所谓“人往高处走、水往低处流”说的是社会和物理的两个不同现象，本质完全一致。就是人和水都在按照各自的势能函数在运动！那么驱动人的势能函数是什么呢？ 人与人的价值不同，就算同一个人，价值观也在改变。本文不讨论这些社会层面的价值观，我们指的是一些最基本的、常识性的、人类共同的价值观。比如说把房间收拾干净了，这是我们的共识。 
1. 伦理、社会规范就是人群在竞争合作之中，受到外部物理环境与因果限制下，达成的暂时的准平衡态。每种平衡态不见得是一个固定的规则，要求大家做同样的规定动作，而是一种概率的“行为的语法”。规则其实就是语法。说到底，这还是一种概率的时空因果与或图STC-AOG的表达。
1. 在社会进化过程中，由于某些边界条件的改变（如新的技术发明，像互联网、人工智能）或者是政策改变（如改革开放），打破了旧的平衡，社会急剧变化；然后，达成新的准平衡态。那么社会规范对应的是另一个时空因果与或图STC-AOG。你拿着一个准平衡态的STC-AOG模型去到另一个准平衡态生活，就出现所谓的“水土不服”现象。 
1. 对比两大类学习方法。 一、归纳学习 Inductive learning。我们通过观察大量数据样本，这些样本就是对某个时期、某个地域、某个人群达成的准平衡态的观察。也是我前面谈过的千年文化的形成与传承。归纳学习的结果就是一个时空因果的概率模型，我把它表达为STC-AOG。每个时空的动作是一个STC-PG，解译图。 二、演绎学习 Deductive learning。这个东西文献中很少，也就是从价值函数（还有物理因果）出发，直接推导出这些准平衡态，在我看来，这也是一个STCAOG。这就要求对研究的对象有深刻的、生成式的模型和理解。比如，诸葛亮到了祁山，先查看地形，知道自己的队伍、粮草情况，摸清楚对手司马懿的情况（包括性格）。然后，他脑袋里面推演，就知道怎么布局了。 人的学习往往是两者的结合。年轻的时候，归纳学习用得多一些，演绎学习往往是一种不成熟冲动，交点学费，但也可能发现了新天地。到了“五十而不惑”的时候，价值观成型了，价值观覆盖的空间也基本齐全了，那么基本上就用演绎学习。
1. 有了这些单个基本任务的地图，机器人就可以做任务的规划。这个规划本身就是一个层次化的表达。文献中有多种方法，我还是把它统一称作一种 STC-PG。这个过程，其实相当复杂，因为它一边做，一边还要不断看和更新场景的模型。因为我前面介绍过，对环境三维形状的计算精度是根据任务需要来决定的，也就是TaskCentered 视觉表达。 这个动作计划的过程还要考虑因果、考虑到场景中别人的反应。考虑的东西越多，它就越成熟，做事就得体、不莽莽撞撞。 
1. 通讯学习的构架里面，就包含了大量的学习模式，包括以下七种学习模式（每种学习模式其实对应与图中的某个或者几个箭头），这里面还有很多模式可以开发出来。 (一)被动统计学习 passive statistical learning：上面刚刚谈到的、当前最流行的学习模式，用大数据拟合模型； (二)主动学习active learning：学生可以问老师主动要数据，这个在机器学习里面也流行过； (三)算法教学algorithmic teaching：老师主动跟踪学生的进展和能力，然后，设计例子来帮你学。这是成本比较高的、理想的优秀教师的教学方式； (四)演示学习learning from demonstration：这是机器人学科里面常用的，就是手把手叫机器人做动作。一个变种是模仿学习immitation learning； (五)感知因果学习perceptual causality：这是我发明的一种，就是通过观察别人行为的因果，而不需要去做实验验证，学习出来的因果模型，这在人类认知中十分普遍； (六)因果学习causal learning：通过动手实验， 控制其它变量， 而得到更可靠的因果模型， 科学实验往往属于这一类；(七)增强学习reinforcement learning：就是去学习决策函数与价值函数的一种方法。 
1. 当前大家做的机器学习，其实是一个很狭义的定义，不代表整个的学习过程。见下图。 它就包含三步： （1）你定义一个损失函数loss function 记作u，代表一个小任务，比如人脸识别，对了就奖励1，错了就是-1。 （2）你 选 择 一 个模型，比如一个 10-层的神经网络，它带有几亿个参数theta，需要通过数据来拟合。 （3）你拿到大量数据，这里假设有人给你准备了标注的数据，然后就开始拟合参数了。 这个过程没有因果，没有机器人行动，是纯粹的、被动的统计学习。目前那些做视觉识别和语音识别都是这一类。其实真正的学习是一个交互的过程。 就像孔子与学生的对话，我们教学生也是这样一个过程。 学生可以问老师，老师问学生，共同思考，是一种平等交流，而不是通过大量题海、填鸭式的训练。坦白说，我虽然是教授，现在就常常从我的博士生那里学到新知识。
1. 深度学习只是这个广义学习构架里面很小的一部分，而学习又是人工智能里面一个领域。所以，把深度学习等同于人工智能，真的是坐井观天、以管窥豹。
1. 物理学把生物的意志排除在研究之外，而这正好是智能科学要研究的对象。智能科学要研究的是一个物理与生物混合的复杂系统。智能作为一种现象，就表现在个体与自然、社会群体的相互作用和行为过程中。我个人相信这些行为和现象必然有统一的力、相互作用、基本元素来描述。其实这些概念对我们搞计算机视觉的人来说一点也不陌生。我们的模型与物理模型是完全相通的，当你有一个概率分布，你就有了“势能函数”，就有了各种“相互作用”， 然后就有了各种“场”与“力”。  
1. 智能科学的复杂之处在于： （1）物 理 学面对的是一个客观的世界，当这个客观世界映射到每个人脑中， 形成一个主观与客观融合的世界，也就是每个人脑中的模型（这是统计中贝叶斯学派观点）。这个模型又被映射到别人脑袋之中。每个脑Mind里面包含了上百个他人的模型的估计。 由这些模型来驱动人的运动、行为。 （2）物理学可以把各种现象隔离出来研究，而我们一张图像就包含大量的模式， 人的一个简单动作后面包含了很复杂的心理活动，很难隔离开。况且，当前以大数据集为依据的“深度学习”学派、“刷榜派”非常流行，你要把一个小问题单独拿出来研究，那在他们复杂数据集里面是讨不到什么便宜的。文章送到他们手上，他们就“强烈拒绝”，要求你到他们数据集上跑结果。这批人缺乏科学的思维和素养。呜呼哀哉！
1. ，我们研究的物理与生物系统有两个基本前提： 一、智能物种与生俱来的任务与价值链条。这是生物进化的“刚需”，动物的行为都是被各种任务驱动的，任务由价值函数决定，而后者是进化论中的phenotype landscape，通俗地说就是进化的适者生存。达尔文进化论中提出来进化这个概念，但没有给出数学描述。后来大家发现，基因突变其实就是物种在这个进化的、大时间尺度上的价值函数中的行动action。我前面那个叠衣服的价值函数地形图，就是从生物学借来的。 二、物理环境客观的现实与因果链条。这就是自然尺度下的物理世界与因果链条，也就是牛顿力学的东西。  说到底，人工智能要变成智能科学，它本质上必将是达尔文与牛顿这两个理论体系的统一。 
1. 我们要建立统一的知识表达：概率和逻辑要融合，和深度学习也要融合。我们看看物理学是如何统一的，他们里面各种模型（四大类的力与相互作用）必须融洽，然后解释各种现象。简单说我们需要搞清楚两点： 一、什么地方用什么模型？ 对比经典力学、电磁学、光学、统计物理、粒子物理等都有自己的现象、规律和使用范围。我们这边也类似，各种模型有它们的范围和基础，比如我们常常听说的，吉布斯模型往往就在高熵区，稀疏模型在低熵区，与或图语法用在中熵区。这一块除了我的实验室，世界上没有其他人研究。 二、这些模型之间如何转化？ 前面我讲了一个例子，我写了一篇关于隐式（马尔科夫场）与显式（稀疏）模型的统一与过渡的信息尺度的论文，投到CVPR会议，结果，三个评分是“（5）强烈拒绝；（5）强烈拒绝；（4）拒绝”。大家根本就没想这个问题，眼睛都巴巴地看着数据集、性能提升了多少。刷榜成了CVPR科研的重要范式。在某些人眼中，刷榜成了唯一方式。我以前是批判这个风气，后来一想，其实应该多鼓励。我对那些把大众带到沟里去的学术领军人物，以前是批评，现在我特别感激Ta们。这样我自己的学生才有更多时间去实现我们的思路。你们都一起涌过来踩踏、乱开乱挖，我都躲不开。我做研究喜欢清静，不去赶热闹，不去追求文章引用率这些指标。


###### [What’s Next For ASML?](https://www.asianometry.com/p/whats-next-for-asml)
1. Both companies (TSMC and ASML) have a strain of “get it done” and "no excuses" culture. They are both very technical. When discussing issues, their focus is almost always on the science and technology. They like geeks and builders.
1. At ASML, people have to be ready to argue and back their points because their peers will challenge them on it. "Challenge" is one of their core values. Perhaps it has a bit to do with the Dutch attitude, which is famously blunt.
1. ASML focuses a great deal on productivity and improving cost of ownership. It is the idea behind the TWINSCAN’s twin scan. ASML's goal is not to make the prettiest or even cheapest machine. Or the machine that most satisfies the armchair semiconductor engineers on Twitter or HackerNews.ASML's goal is to make a machine that offers the best value for its customers - the most accurate and productive machine possible. Even a billion dollar machine can make sense for the fab if it can accurately do enough wafers per hour.
1. Despite the fact that ASML’s product is a physical thing, it seems like only a minority of its employees work the factory floors. Most work in offices - sales, software, and the such.
1. The people at ASML are aware that High-NA EUV does not work, right now. There are many problems. There is more than a little skepticism floating around, particularly on the Internet.But the company has faced similar doubts before. TWINSCAN, 193 nanometer immersion, and EUV all did not work at the beginning too. The first EUV machine took 23 hours to pattern a single wafer. Today’s best EUV machines can do 180 wafers per hour.The key thing was to get going on it, and to work closely with the fabs and the rest of the semiconductor ecosystem to eventually get there. If there is a pathway to making it work, then that is enough.To me, that is the sort of technological optimism that we all need to have more of in our lives.


### 有趣
###### [微软面试题](https://blog.jgc.org/2024/09/steve-ballmers-binary-search-interview.html)
Steve Ballmer觉得面试有3点很重要：1）motivation；2)学校学到的知识；3）解决问题的能力。并以猜数字为例示范了一道面试题，同时考察期望和二分法。
###### [参观光刻机厂商ASML:What’s Next For ASML?](https://www.asianometry.com/p/whats-next-for-asml)

### 荐书


### 杂谈


![](/img/wc-tail.GIF)
